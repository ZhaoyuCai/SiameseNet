{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from torch import optim\n",
    "from torchvision import models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNet(nn.Module):\n",
    "    def __init__(self, hidden_size = [256, 100], label_size=None):\n",
    "        super(SiameseNet, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.label = (label_size is None)\n",
    "        \n",
    "        # ResNet requires the input to be the size of [batch_size, 3, 224, 224]\n",
    "        self.ResNet34 = models.resnet34(pretrained=True)\n",
    "        for param in self.ResNet34.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.ResNet34.fc = nn.Linear(512, hidden_size[0])\n",
    "        self.ResNet34.fc.requires_grad = True\n",
    "        \n",
    "        self.FC1 = nn.Linear(2 * hidden_size[0], hidden_size[1])\n",
    "        \n",
    "        if self.label:\n",
    "            self.Output = nn.Linear(hidden_size[1], label_size)\n",
    "        else:\n",
    "            self.Output = nn.Linear(hidden_size[1], 1)\n",
    "    \n",
    "    def forward(self, img1, img2):\n",
    "        out1 = self.ResNet34(img1).view(-1, self.hidden_size[0])\n",
    "        out2 = self.ResNet34(img2).view(-1, self.hidden_size[0])\n",
    "        out = torch.cat([out1, out2], dim=1)\n",
    "        out = F.tanh(self.FC1(out))\n",
    "        \n",
    "        if self.label:\n",
    "            out = F.softmax(self.Output(out))\n",
    "        else:\n",
    "            out = self.Output(out)\n",
    "        return out\n",
    "    \n",
    "    def save(self, filename='SiameseNet_checkpoint.pt', is_best=False, epoch = ''):\n",
    "        torch.save(self.state_dict(), filename)\n",
    "        if is_best:\n",
    "            toch.save(self.state_dict(), 'SiameseNet_best.pt')\n",
    "    \n",
    "    def load(self, filename='SiameseNet_checkpoint.pt'):\n",
    "        self.load_state_dict(torch.load(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, hidden_size = [256, 100], label_size=None):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.label = (label_size is None)\n",
    "        \n",
    "        # ResNet requires the input to be the size of [batch_size, 3, 224, 224]\n",
    "        self.ResNet34 = models.resnet34(pretrained=True)\n",
    "        for param in self.ResNet34.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.ResNet34.fc = nn.Linear(512, hidden_size[0])\n",
    "        self.ResNet34.fc.requires_grad = True\n",
    "        \n",
    "        self.FC1 = nn.Linear(hidden_size[0], hidden_size[1])\n",
    "        \n",
    "        if self.label:\n",
    "            self.Output = nn.Linear(hidden_size[1], label_size)\n",
    "        else:\n",
    "            self.Output = nn.Linear(hidden_size[1], 1)\n",
    "    \n",
    "    def forward(self, img):\n",
    "        out = F.tanh(self.ResNet34(img).view(-1, self.hidden_size[0]))\n",
    "        out = F.tanh(self.FC1(out))\n",
    "        out = self.Output(out)\n",
    "        \n",
    "        if self.label:\n",
    "            out = F.softmax(self.Output(out))\n",
    "        else:\n",
    "            out = self.Output(out)\n",
    "        return out\n",
    "    \n",
    "    def save(self, filename='ConvNet_checkpoint.pt', is_best=False, epoch = ''):\n",
    "        torch.save(self.state_dict(), filename)\n",
    "        if is_best:\n",
    "            toch.save(self.state_dict(), 'ConvNet_best.pt')\n",
    "    \n",
    "    def load(self, filename='ConvNet_checkpoint.pt'):\n",
    "        self.load_state_dict(torch.load(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = Variable(torch.rand(32, 3, 224, 224)).cuda()\n",
    "x2 = Variable(torch.rand(32, 3, 224, 224)).cuda()\n",
    "diff = Variable(torch.rand(32, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, num_classes = 32, 3\n",
    "label_type = None\n",
    "\n",
    "model = SiameseNet().cuda()\n",
    "# y_pred = model.forward(x1, x2)\n",
    "criterion = nn.MSELoss()\n",
    "if label_type and label_type == 'categorical':\n",
    "    criterion == nn.CrossEntropyLoss()\n",
    "params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = optim.Adam(params, lr=0.0001)\n",
    "\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(input, target):\n",
    "    return torch.sum((input - target) ** 2) / input.data.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.4023, device='cuda:0')\n",
      "100 tensor(1.00000e-06 *\n",
      "       9.0790, device='cuda:0')\n",
      "tensor([[ 0.1652],\n",
      "        [ 0.6762],\n",
      "        [ 0.0152],\n",
      "        [ 0.5734],\n",
      "        [ 0.2580],\n",
      "        [ 0.7373],\n",
      "        [ 0.1691],\n",
      "        [ 0.6825],\n",
      "        [ 0.0103],\n",
      "        [ 0.7213],\n",
      "        [ 0.0739],\n",
      "        [ 0.8589],\n",
      "        [ 0.0918],\n",
      "        [ 0.3416],\n",
      "        [ 0.0079],\n",
      "        [ 0.6057],\n",
      "        [ 0.2454],\n",
      "        [ 0.9355],\n",
      "        [ 0.9538],\n",
      "        [ 0.6154],\n",
      "        [ 0.1043],\n",
      "        [ 0.4078],\n",
      "        [ 0.7000],\n",
      "        [ 0.6773],\n",
      "        [ 0.5595],\n",
      "        [ 0.9438],\n",
      "        [ 0.7610],\n",
      "        [ 0.6861],\n",
      "        [ 0.6761],\n",
      "        [ 0.6715],\n",
      "        [ 0.1691],\n",
      "        [ 0.3603]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    # Forward pass\n",
    "    diff_pred = model.forward(x1, x2)\n",
    "    \n",
    "    # compute and print loss\n",
    "    loss = mse_loss(diff_pred, diff)\n",
    "    losses.append(loss.data)\n",
    "    if epoch % 100 == 0:\n",
    "        print(epoch, loss.data)\n",
    "        \n",
    "    # zero grads\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(model.forward(x1, x2))\n",
    "model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1652],\n",
      "        [ 0.6762],\n",
      "        [ 0.0152],\n",
      "        [ 0.5734],\n",
      "        [ 0.2580],\n",
      "        [ 0.7373],\n",
      "        [ 0.1691],\n",
      "        [ 0.6825],\n",
      "        [ 0.0103],\n",
      "        [ 0.7213],\n",
      "        [ 0.0739],\n",
      "        [ 0.8589],\n",
      "        [ 0.0918],\n",
      "        [ 0.3416],\n",
      "        [ 0.0079],\n",
      "        [ 0.6057],\n",
      "        [ 0.2454],\n",
      "        [ 0.9355],\n",
      "        [ 0.9538],\n",
      "        [ 0.6154],\n",
      "        [ 0.1043],\n",
      "        [ 0.4078],\n",
      "        [ 0.7000],\n",
      "        [ 0.6773],\n",
      "        [ 0.5595],\n",
      "        [ 0.9438],\n",
      "        [ 0.7610],\n",
      "        [ 0.6861],\n",
      "        [ 0.6761],\n",
      "        [ 0.6715],\n",
      "        [ 0.1691],\n",
      "        [ 0.3603]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model2 = SiameseNet().cuda()\n",
    "model2.load()\n",
    "\n",
    "print(model2.forward(x1, x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, num_classes = 32, 3\n",
    "label_type = None\n",
    "\n",
    "conv_model = ConvNet().cuda()\n",
    "# y_pred = model.forward(x1, x2)\n",
    "conv_criterion = nn.MSELoss()\n",
    "if label_type and label_type == 'categorical':\n",
    "    conv_criterion == nn.CrossEntropyLoss()\n",
    "conv_params = filter(lambda p: p.requires_grad, conv_model.parameters())\n",
    "conv_optimizer = optim.Adam(conv_params, lr=0.0001)\n",
    "\n",
    "conv_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.2059, device='cuda:0')\n",
      "100 tensor(1.00000e-05 *\n",
      "       1.9060, device='cuda:0')\n",
      "200 tensor(1.00000e-10 *\n",
      "       5.5764, device='cuda:0')\n",
      "tensor([[ 0.1652],\n",
      "        [ 0.6762],\n",
      "        [ 0.0152],\n",
      "        [ 0.5734],\n",
      "        [ 0.2580],\n",
      "        [ 0.7373],\n",
      "        [ 0.1690],\n",
      "        [ 0.6826],\n",
      "        [ 0.0103],\n",
      "        [ 0.7213],\n",
      "        [ 0.0739],\n",
      "        [ 0.8590],\n",
      "        [ 0.0918],\n",
      "        [ 0.3416],\n",
      "        [ 0.0078],\n",
      "        [ 0.6057],\n",
      "        [ 0.2454],\n",
      "        [ 0.9355],\n",
      "        [ 0.9538],\n",
      "        [ 0.6154],\n",
      "        [ 0.1043],\n",
      "        [ 0.4078],\n",
      "        [ 0.7000],\n",
      "        [ 0.6773],\n",
      "        [ 0.5595],\n",
      "        [ 0.9438],\n",
      "        [ 0.7610],\n",
      "        [ 0.6861],\n",
      "        [ 0.6761],\n",
      "        [ 0.6715],\n",
      "        [ 0.1691],\n",
      "        [ 0.3603]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(300):\n",
    "    # Forward pass\n",
    "    diff_pred = conv_model.forward(x1)\n",
    "    \n",
    "    # compute and print loss\n",
    "    conv_loss = mse_loss(diff_pred, diff)\n",
    "    conv_losses.append(conv_loss.data)\n",
    "    if epoch % 100 == 0:\n",
    "        print(epoch, conv_loss.data)\n",
    "        \n",
    "    # zero grads\n",
    "    conv_optimizer.zero_grad()\n",
    "    conv_loss.backward()\n",
    "    conv_optimizer.step()\n",
    "\n",
    "print(conv_model.forward(x1))\n",
    "conv_model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = Variable(torch.rand(32, 3, 224, 224)).cuda()\n",
    "x2 = Variable(torch.rand(32, 3, 224, 224)).cuda()\n",
    "label = np.random.randint(0, 3, size = (32, 1))\n",
    "label = Variable(torch.Tensor(label)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, num_classes = 32, 3\n",
    "label_size = 3\n",
    "\n",
    "model = SiameseNet(label_size=label_size).cuda()\n",
    "# y_pred = model.forward(x1, x2)\n",
    "criterion = mse_loss\n",
    "if model.label:\n",
    "    criterion == nn.CrossEntropyLoss()\n",
    "params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = optim.Adam(params, lr=0.0001)\n",
    "\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(1.6094, device='cuda:0')\n",
      "100 tensor(1.00000e-04 *\n",
      "       2.4110, device='cuda:0')\n",
      "tensor([[ 2.0000e+00],\n",
      "        [ 2.0000e+00],\n",
      "        [-5.0731e-05],\n",
      "        [ 2.0000e+00],\n",
      "        [ 5.7913e-05],\n",
      "        [ 1.0245e-04],\n",
      "        [-1.4190e-04],\n",
      "        [ 1.0001e+00],\n",
      "        [ 1.0000e+00],\n",
      "        [ 1.0000e+00],\n",
      "        [ 1.9999e+00],\n",
      "        [ 2.0001e+00],\n",
      "        [-1.7934e-05],\n",
      "        [-7.1667e-05],\n",
      "        [ 2.0001e+00],\n",
      "        [ 1.0000e+00],\n",
      "        [ 1.1995e-06],\n",
      "        [ 1.9998e+00],\n",
      "        [ 9.9988e-01],\n",
      "        [ 9.9988e-01],\n",
      "        [ 9.9996e-01],\n",
      "        [ 3.9242e-05],\n",
      "        [-1.1883e-04],\n",
      "        [ 2.0000e+00],\n",
      "        [ 1.9999e+00],\n",
      "        [ 1.0000e+00],\n",
      "        [ 2.0001e+00],\n",
      "        [ 1.0000e+00],\n",
      "        [ 6.6601e-05],\n",
      "        [ 2.0000e+00],\n",
      "        [ 1.9999e+00],\n",
      "        [ 2.0000e+00]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    # Forward pass\n",
    "    label_pred = model.forward(x1, x2)\n",
    "    \n",
    "    # compute and print loss\n",
    "    loss = criterion(label_pred, label)\n",
    "\n",
    "    losses.append(loss.data)\n",
    "    if epoch % 100 == 0:\n",
    "        print(epoch, loss.data)\n",
    "        \n",
    "    # zero grads\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(model.forward(x1, x2))\n",
    "#model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
