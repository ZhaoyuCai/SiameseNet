{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from torch import optim\n",
    "from torchvision import models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNet(nn.Module):\n",
    "    def __init__(self, hidden_size = [256, 100], label_size=None):\n",
    "        super(SiameseNet, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.label = not (label_size is None)\n",
    "        \n",
    "        # ResNet requires the input to be the size of [batch_size, 3, 224, 224]\n",
    "        self.ResNet34 = models.resnet34(pretrained=True)\n",
    "        for param in self.ResNet34.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.ResNet34.fc = nn.Linear(512, hidden_size[0])\n",
    "        self.ResNet34.fc.requires_grad = True\n",
    "        \n",
    "        self.FC1 = nn.Linear(2 * hidden_size[0], hidden_size[1])\n",
    "        \n",
    "        if self.label:\n",
    "            self.Output = nn.Linear(hidden_size[1], label_size)\n",
    "        else:\n",
    "            self.Output = nn.Linear(hidden_size[1], 1)\n",
    "    \n",
    "    def forward(self, img1, img2):\n",
    "        out1 = self.ResNet34(img1).view(-1, self.hidden_size[0])\n",
    "        out2 = self.ResNet34(img2).view(-1, self.hidden_size[0])\n",
    "        out = torch.cat([out1, out2], dim=1)\n",
    "        out = F.tanh(self.FC1(out))\n",
    "        \n",
    "        if self.label:\n",
    "            out = F.log_softmax(self.Output(out), dim=1)\n",
    "        else:\n",
    "            out = self.Output(out)\n",
    "        return out\n",
    "    \n",
    "    def save(self, filename='SiameseNet_checkpoint.pt', is_best=False, epoch = ''):\n",
    "        torch.save(self.state_dict(), filename)\n",
    "        if is_best:\n",
    "            toch.save(self.state_dict(), 'SiameseNet_best.pt')\n",
    "    \n",
    "    def load(self, filename='SiameseNet_checkpoint.pt'):\n",
    "        self.load_state_dict(torch.load(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, hidden_size = [256, 100], label_size=None):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.label = not (label_size is None)\n",
    "        \n",
    "        # ResNet requires the input to be the size of [batch_size, 3, 224, 224]\n",
    "        self.ResNet34 = models.resnet34(pretrained=True)\n",
    "        for param in self.ResNet34.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.ResNet34.fc = nn.Linear(512, hidden_size[0])\n",
    "        self.ResNet34.fc.requires_grad = True\n",
    "        \n",
    "        self.FC1 = nn.Linear(hidden_size[0], hidden_size[1])\n",
    "        \n",
    "        if self.label:\n",
    "            self.Output = nn.Linear(hidden_size[1], label_size)\n",
    "        else:\n",
    "            self.Output = nn.Linear(hidden_size[1], 1)\n",
    "    \n",
    "    def forward(self, img):\n",
    "        out = F.tanh(self.ResNet34(img).view(-1, self.hidden_size[0]))\n",
    "        out = F.tanh(self.FC1(out))\n",
    "        out = self.Output(out)\n",
    "        \n",
    "        if self.label:\n",
    "            out = F.log_softmax(self.Output(out), dim=1)\n",
    "        else:\n",
    "            out = self.Output(out)\n",
    "        return out\n",
    "    \n",
    "    def save(self, filename='ConvNet_checkpoint.pt', is_best=False, epoch = ''):\n",
    "        torch.save(self.state_dict(), filename)\n",
    "        if is_best:\n",
    "            toch.save(self.state_dict(), 'ConvNet_best.pt')\n",
    "    \n",
    "    def load(self, filename='ConvNet_checkpoint.pt'):\n",
    "        self.load_state_dict(torch.load(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = Variable(torch.rand(32, 3, 224, 224)).cuda()\n",
    "x2 = Variable(torch.rand(32, 3, 224, 224)).cuda()\n",
    "diff = Variable(torch.rand(32, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, num_classes = 32, 3\n",
    "label_type = None\n",
    "\n",
    "model = SiameseNet().cuda()\n",
    "# y_pred = model.forward(x1, x2)\n",
    "criterion = nn.MSELoss()\n",
    "if label_type and label_type == 'categorical':\n",
    "    criterion == nn.CrossEntropyLoss()\n",
    "params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = optim.Adam(params, lr=0.0001)\n",
    "\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(input, target):\n",
    "    return torch.sum((input - target) ** 2) / input.data.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.4023, device='cuda:0')\n",
      "100 tensor(1.00000e-06 *\n",
      "       9.0790, device='cuda:0')\n",
      "tensor([[ 0.1652],\n",
      "        [ 0.6762],\n",
      "        [ 0.0152],\n",
      "        [ 0.5734],\n",
      "        [ 0.2580],\n",
      "        [ 0.7373],\n",
      "        [ 0.1691],\n",
      "        [ 0.6825],\n",
      "        [ 0.0103],\n",
      "        [ 0.7213],\n",
      "        [ 0.0739],\n",
      "        [ 0.8589],\n",
      "        [ 0.0918],\n",
      "        [ 0.3416],\n",
      "        [ 0.0079],\n",
      "        [ 0.6057],\n",
      "        [ 0.2454],\n",
      "        [ 0.9355],\n",
      "        [ 0.9538],\n",
      "        [ 0.6154],\n",
      "        [ 0.1043],\n",
      "        [ 0.4078],\n",
      "        [ 0.7000],\n",
      "        [ 0.6773],\n",
      "        [ 0.5595],\n",
      "        [ 0.9438],\n",
      "        [ 0.7610],\n",
      "        [ 0.6861],\n",
      "        [ 0.6761],\n",
      "        [ 0.6715],\n",
      "        [ 0.1691],\n",
      "        [ 0.3603]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    # Forward pass\n",
    "    diff_pred = model.forward(x1, x2)\n",
    "    \n",
    "    # compute and print loss\n",
    "    loss = mse_loss(diff_pred, diff)\n",
    "    losses.append(loss.data)\n",
    "    if epoch % 100 == 0:\n",
    "        print(epoch, loss.data)\n",
    "        \n",
    "    # zero grads\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(model.forward(x1, x2))\n",
    "model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1652],\n",
      "        [ 0.6762],\n",
      "        [ 0.0152],\n",
      "        [ 0.5734],\n",
      "        [ 0.2580],\n",
      "        [ 0.7373],\n",
      "        [ 0.1691],\n",
      "        [ 0.6825],\n",
      "        [ 0.0103],\n",
      "        [ 0.7213],\n",
      "        [ 0.0739],\n",
      "        [ 0.8589],\n",
      "        [ 0.0918],\n",
      "        [ 0.3416],\n",
      "        [ 0.0079],\n",
      "        [ 0.6057],\n",
      "        [ 0.2454],\n",
      "        [ 0.9355],\n",
      "        [ 0.9538],\n",
      "        [ 0.6154],\n",
      "        [ 0.1043],\n",
      "        [ 0.4078],\n",
      "        [ 0.7000],\n",
      "        [ 0.6773],\n",
      "        [ 0.5595],\n",
      "        [ 0.9438],\n",
      "        [ 0.7610],\n",
      "        [ 0.6861],\n",
      "        [ 0.6761],\n",
      "        [ 0.6715],\n",
      "        [ 0.1691],\n",
      "        [ 0.3603]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model2 = SiameseNet().cuda()\n",
    "model2.load()\n",
    "\n",
    "print(model2.forward(x1, x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, num_classes = 32, 3\n",
    "label_type = None\n",
    "\n",
    "conv_model = ConvNet().cuda()\n",
    "# y_pred = model.forward(x1, x2)\n",
    "conv_criterion = nn.MSELoss()\n",
    "if label_type and label_type == 'categorical':\n",
    "    conv_criterion == nn.CrossEntropyLoss()\n",
    "conv_params = filter(lambda p: p.requires_grad, conv_model.parameters())\n",
    "conv_optimizer = optim.Adam(conv_params, lr=0.0001)\n",
    "\n",
    "conv_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.2059, device='cuda:0')\n",
      "100 tensor(1.00000e-05 *\n",
      "       1.9060, device='cuda:0')\n",
      "200 tensor(1.00000e-10 *\n",
      "       5.5764, device='cuda:0')\n",
      "tensor([[ 0.1652],\n",
      "        [ 0.6762],\n",
      "        [ 0.0152],\n",
      "        [ 0.5734],\n",
      "        [ 0.2580],\n",
      "        [ 0.7373],\n",
      "        [ 0.1690],\n",
      "        [ 0.6826],\n",
      "        [ 0.0103],\n",
      "        [ 0.7213],\n",
      "        [ 0.0739],\n",
      "        [ 0.8590],\n",
      "        [ 0.0918],\n",
      "        [ 0.3416],\n",
      "        [ 0.0078],\n",
      "        [ 0.6057],\n",
      "        [ 0.2454],\n",
      "        [ 0.9355],\n",
      "        [ 0.9538],\n",
      "        [ 0.6154],\n",
      "        [ 0.1043],\n",
      "        [ 0.4078],\n",
      "        [ 0.7000],\n",
      "        [ 0.6773],\n",
      "        [ 0.5595],\n",
      "        [ 0.9438],\n",
      "        [ 0.7610],\n",
      "        [ 0.6861],\n",
      "        [ 0.6761],\n",
      "        [ 0.6715],\n",
      "        [ 0.1691],\n",
      "        [ 0.3603]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(300):\n",
    "    # Forward pass\n",
    "    diff_pred = conv_model.forward(x1)\n",
    "    \n",
    "    # compute and print loss\n",
    "    conv_loss = mse_loss(diff_pred, diff)\n",
    "    conv_losses.append(conv_loss.data)\n",
    "    if epoch % 100 == 0:\n",
    "        print(epoch, conv_loss.data)\n",
    "        \n",
    "    # zero grads\n",
    "    conv_optimizer.zero_grad()\n",
    "    conv_loss.backward()\n",
    "    conv_optimizer.step()\n",
    "\n",
    "print(conv_model.forward(x1))\n",
    "conv_model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = Variable(torch.rand(32, 3, 224, 224)).cuda()\n",
    "x2 = Variable(torch.rand(32, 3, 224, 224)).cuda()\n",
    "\n",
    "\n",
    "label = np.random.randint(0, 3, size = (32))\n",
    "\n",
    "# label = np.zeros((32, 3))\n",
    "# label[np.arange(32),l] = 1\n",
    "label = Variable(torch.LongTensor(label)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, num_classes = 32, 3\n",
    "label_size = 3\n",
    "\n",
    "model = SiameseNet(label_size=label_size).cuda()\n",
    "# y_pred = model.forward(x1, x2)\n",
    "criterion = mse_loss\n",
    "if model.label:\n",
    "    criterion = nn.NLLLoss()\n",
    "params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = optim.Adam(params, lr=0.0001)\n",
    "\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(1.1174, device='cuda:0')\n",
      "100 tensor(1.00000e-02 *\n",
      "       3.7156, device='cuda:0')\n",
      "tensor([[-5.1935, -5.2931, -0.0106],\n",
      "        [-5.2222, -0.0109, -5.2154],\n",
      "        [-5.1752, -0.0119, -5.0948],\n",
      "        [-0.0130, -4.9900, -5.0921],\n",
      "        [-0.0133, -5.1911, -4.8708],\n",
      "        [-5.8757, -5.5079, -0.0069],\n",
      "        [-0.0129, -5.1289, -4.9755],\n",
      "        [-5.3828, -5.0378, -0.0111],\n",
      "        [-5.5228, -5.2418, -0.0093],\n",
      "        [-5.0468, -0.0134, -4.9795],\n",
      "        [-0.0141, -5.0429, -4.8811],\n",
      "        [-5.6805, -5.7174, -0.0067],\n",
      "        [-5.2797, -5.4151, -0.0096],\n",
      "        [-5.4372, -0.0127, -4.7956],\n",
      "        [-5.5212, -5.7237, -0.0073],\n",
      "        [-0.0122, -4.8687, -5.4153],\n",
      "        [-5.1719, -5.2274, -0.0111],\n",
      "        [-0.0130, -5.3890, -4.7814],\n",
      "        [-5.0544, -0.0141, -4.8724],\n",
      "        [-5.4260, -4.7339, -0.0133],\n",
      "        [-5.3204, -0.0117, -4.9953],\n",
      "        [-5.6313, -5.2479, -0.0089],\n",
      "        [-0.0112, -5.1604, -5.2263],\n",
      "        [-5.4634, -5.5149, -0.0083],\n",
      "        [-5.1924, -0.0124, -4.9902],\n",
      "        [-5.0031, -0.0120, -5.2500],\n",
      "        [-5.2342, -5.2398, -0.0107],\n",
      "        [-5.1887, -5.7249, -0.0089],\n",
      "        [-4.9434, -5.6986, -0.0105],\n",
      "        [-6.0116, -0.0091, -5.0205],\n",
      "        [-5.3501, -0.0131, -4.7972],\n",
      "        [-0.0150, -4.9570, -4.8430]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    # Forward pass\n",
    "    label_pred = model.forward(x1, x2)\n",
    "    \n",
    "    # compute and print loss\n",
    "    loss = criterion(label_pred, label)\n",
    "\n",
    "    losses.append(loss.data)\n",
    "    if epoch % 100 == 0:\n",
    "        print(epoch, loss.data)\n",
    "        \n",
    "    # zero grads\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(model.forward(x1, x2))\n",
    "#model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
